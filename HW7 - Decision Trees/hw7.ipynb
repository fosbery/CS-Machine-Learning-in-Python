{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Decision Trees\n",
    "\n",
    "_**NOTE**: this assignment is only mandatory for students registered for CSC 8515; students registered for CSC 4515 are **not** required to complete this assignment._\n",
    "\n",
    "For this assignment, your goal is to implement the ID3 algorithm (greedy information-gain based decision tree induction).  You should use the Congressional Voting Records data set, the same one that we used with Naive Bayes, and for the same reason; it is a discrete multivariate dataset, which is well suited to decision trees.  \n",
    "\n",
    "Note that while scikit-learn does have decision trees, it doesn't really handle discrete data well, so the library version may not produce exactly the same trees that your algorithm will.\n",
    "\n",
    "Implement and test your algorithm; be sure you can print the actual tree (a simple text-based visualization is fine), as well as calculating classification accuracy on held-out testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSC 8515 - Machine Learning  \n",
    "Assignment 7  \n",
    "Scaffolding by Dr. Ben Mitchell  \n",
    "Assignment completed by: James Fung  **\n",
    "\n",
    "Some resources used:\n",
    "https://stackoverflow.com/questions/10148818/numpy-how-to-iterate-over-columns-of-array\n",
    "https://stackoverflow.com/questions/47448931/why-cant-i-iterate-through-nested-keys\n",
    "https://stackoverflow.com/questions/40434121/recursive-programming-in-decision-tree\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section: **Data manipulation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Column names.\n",
    "colNames = ['party']\n",
    "for i in range(16):\n",
    "    colNames.append('Bill '+str(i))\n",
    "\n",
    "#Read the data.\n",
    "voting = pd.read_csv('house-votes-84.data', header=None, names=colNames )\n",
    "\n",
    "#Shuffle data on 70/30.\n",
    "shuffled = voting.sample(frac=1)\n",
    "trainFrac = 0.7\n",
    "trainCount = int(len(voting) * trainFrac)\n",
    "train = shuffled[:trainCount]\n",
    "test = shuffled[trainCount:]\n",
    "\n",
    "#Arrays with labels will be used for my implementation.\n",
    "trainnumpy = train.values\n",
    "testnumpy = test.values\n",
    "\n",
    "#Arrays that are split apart are used for sklearns.\n",
    "trainLabels = train['party'].values #Pull out just the column party without the row indexes. \n",
    "testLabels = test['party'].values\n",
    "trainFeatures = train.drop(['party'], axis=1).values #Drop column as opposed to row, default is axis = 0.\n",
    "testFeatures = test.drop(['party'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: My own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to count number of times a class appears.\n",
    "def uniquecounts(data):\n",
    "    results={}\n",
    "    for row in data:\n",
    "        r=row[len(row)-1]\n",
    "        if r not in results: results[r]=0\n",
    "        results[r]+=1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Entropy.\n",
    "def entropy(data):\n",
    "    import math\n",
    "    counts=uniquecounts(data)\n",
    "    ent=0.0\n",
    "    for classes in counts.keys():\n",
    "        p=float(counts[classes])/len(data)\n",
    "        ent=ent-p*math.log2(p)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function that will subset the dataset. This will be used for placing data into each child node. \n",
    "\n",
    "def subset(data,column,value):\n",
    "    #Create an empty numpy array.\n",
    "    newdata = np.empty((0,data.shape[1]))\n",
    "    #Skip the labels.\n",
    "    row = 1\n",
    "    while row < data.shape[0]:\n",
    "        #Subset on value.\n",
    "        if data[row][column] == value:\n",
    "            newdata = np.vstack((newdata,data[row]))\n",
    "            row+=1\n",
    "        #Skip row if value is not met.\n",
    "        else:\n",
    "            row+=1\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function that will locate the best feature to divide the set.\n",
    "\n",
    "def bestfeature(data):\n",
    "    #Entropy of the dataset.\n",
    "    baseentropy = entropy(data)\n",
    "    #Initialize best information gain and best feature.\n",
    "    bestig = float('inf')\n",
    "    bestfeature = 0\n",
    "    #Skip the class labels.\n",
    "    col = 1\n",
    "    while col < data.shape[1]:\n",
    "        #Skip column if entirely pure.\n",
    "        if entropy(data[:,col]) == 0:\n",
    "            col += 1\n",
    "        #Calculate information gain.\n",
    "        elif baseentropy-entropy(data[:,col]) < bestig:\n",
    "            bestig = baseentropy-entropy(data[:,col])\n",
    "            bestfeature = col\n",
    "        col += 1\n",
    "    return bestfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decisiontree(data,tree=None):\n",
    "    \n",
    "    #Find best feature.\n",
    "    node = bestfeature(data)\n",
    "    \n",
    "    #Dictionary for tree - I don't think this is optimal but works for now.\n",
    "    if tree is None:\n",
    "        tree = {}\n",
    "        tree[node] = {}\n",
    "    \n",
    "    #Used for splitting the data into subsets.\n",
    "    features = np.unique(data[:,node])\n",
    "    \n",
    "    #Split the data.\n",
    "    for feature in features:\n",
    "        childdata = subset(data,node,feature)\n",
    "        #Count how many times each label appears in each child node.\n",
    "        label,count = np.unique(childdata[:,0],return_counts=True)\n",
    "        \n",
    "        #Check for purity.\n",
    "        if len(count) == 1:\n",
    "            tree[node][feature] = label[0]\n",
    "        #Recurse.\n",
    "        else:\n",
    "            tree[node][feature] = decisiontree(childdata)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'?': {1: {'?': {6: {'?': {9: {'?': 'republican', 'y': {0: {}}}},\n",
       "      'n': 'democrat',\n",
       "      'y': {3: {'?': {0: {}}, 'n': 'democrat'}}}},\n",
       "    'n': {3: {'?': 'republican',\n",
       "      'n': {16: {'?': {5: {'n': {0: {}}, 'y': 'republican'}},\n",
       "        'n': 'republican',\n",
       "        'y': 'republican'}},\n",
       "      'y': {5: {'?': 'democrat',\n",
       "        'n': 'democrat',\n",
       "        'y': {11: {'n': {0: {}}, 'y': 'democrat'}}}}}},\n",
       "    'y': {13: {'?': 'republican',\n",
       "      'n': 'democrat',\n",
       "      'y': {3: {'n': 'republican', 'y': 'democrat'}}}}}},\n",
       "  'n': {16: {'?': {6: {'?': 'democrat',\n",
       "      'n': 'democrat',\n",
       "      'y': {9: {'?': 'democrat', 'n': 'republican', 'y': 'democrat'}}}},\n",
       "    'n': {11: {'?': {3: {'n': {0: {}}, 'y': 'democrat'}},\n",
       "      'n': {10: {'n': {13: {'n': 'republican', 'y': 'republican'}},\n",
       "        'y': 'republican'}},\n",
       "      'y': 'democrat'}},\n",
       "    'y': {15: {'?': {5: {'n': 'democrat',\n",
       "        'y': {3: {'n': 'republican', 'y': {0: {}}}}}},\n",
       "      'n': {8: {'?': 'republican',\n",
       "        'n': {11: {'?': 'republican',\n",
       "          'n': {10: {'n': {4: {'n': 'democrat', 'y': 'republican'}},\n",
       "            'y': 'republican'}},\n",
       "          'y': {7: {'n': 'democrat', 'y': 'republican'}}}},\n",
       "        'y': {1: {'?': 'republican',\n",
       "          'n': {5: {'n': 'democrat', 'y': 'republican'}},\n",
       "          'y': {13: {'?': 'democrat',\n",
       "            'n': {14: {'n': 'democrat',\n",
       "              'y': {3: {'n': {0: {}}, 'y': 'democrat'}}}},\n",
       "            'y': 'democrat'}}}}}},\n",
       "      'y': {14: {'?': 'democrat',\n",
       "        'n': 'democrat',\n",
       "        'y': {12: {'?': 'republican',\n",
       "          'n': {4: {'n': 'democrat', 'y': 'republican'}},\n",
       "          'y': {1: {'n': 'republican', 'y': 'republican'}}}}}}}}}},\n",
       "  'y': {16: {'?': {13: {'?': {8: {'?': 'republican',\n",
       "        'n': 'republican',\n",
       "        'y': 'democrat'}},\n",
       "      'n': 'democrat',\n",
       "      'y': {8: {'?': {1: {'n': 'republican', 'y': {0: {}}}},\n",
       "        'n': {4: {'n': 'democrat', 'y': 'republican'}},\n",
       "        'y': 'democrat'}}}},\n",
       "    'n': {12: {'?': {1: {'n': 'republican', 'y': 'democrat'}},\n",
       "      'n': {1: {'n': {0: {}}, 'y': {5: {'n': {0: {}}, 'y': 'republican'}}}},\n",
       "      'y': {11: {'n': 'republican',\n",
       "        'y': {1: {'n': {3: {'n': 'republican', 'y': 'democrat'}},\n",
       "          'y': 'republican'}}}}}},\n",
       "    'y': {9: {'?': 'democrat',\n",
       "      'n': {11: {'?': {1: {'n': {3: {'n': {0: {}}, 'y': 'democrat'}},\n",
       "          'y': {0: {}}}},\n",
       "        'n': {8: {'?': 'republican',\n",
       "          'n': {1: {'n': {10: {'n': {12: {'n': {3: {'n': 'republican',\n",
       "                  'y': {0: {}}}},\n",
       "                'y': 'republican'}},\n",
       "              'y': 'republican'}},\n",
       "            'y': 'republican'}},\n",
       "          'y': {1: {'n': 'democrat',\n",
       "            'y': {5: {'n': 'democrat', 'y': {0: {}}}}}}}},\n",
       "        'y': {14: {'?': 'democrat',\n",
       "          'n': {6: {'?': 'democrat',\n",
       "            'y': {3: {'n': 'republican', 'y': {0: {}}}}}},\n",
       "          'y': {1: {'n': {7: {'n': 'republican', 'y': 'republican'}},\n",
       "            'y': {4: {'n': 'democrat', 'y': 'republican'}}}}}}}},\n",
       "      'y': {13: {'?': 'democrat',\n",
       "        'n': 'democrat',\n",
       "        'y': {4: {'?': 'democrat',\n",
       "          'n': 'democrat',\n",
       "          'y': {3: {'n': 'republican', 'y': 'republican'}}}}}}}}}}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the tree on the training set, print the tree.\n",
    "tree = decisiontree(trainnumpy)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'democrat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict new cases.\n",
    "def predict(test,tree):\n",
    "    for nodes in tree.keys():        \n",
    "        value = test[nodes]\n",
    "        tree = tree[nodes][value]\n",
    "        #If it has not yet hit the bottom node, recurse. This is done by checking to see if the child node is a dict.\n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(test, tree)\n",
    "        #Return class label and break.\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break                       \n",
    "    return prediction\n",
    "\n",
    "#Test example.\n",
    "predict(testnumpy[0],tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8702290076335878"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the tree on the test set, calculate accuracy.\n",
    "\n",
    "counter = 0\n",
    "for i in range(0,len(testnumpy)-1):\n",
    "    #For some reason, my code broke on a few examples where it was not able to find a resulting subkey, so on those\n",
    "    #occurances I randomly selected a class label. Seems to occur on \"?\" for random columns.\n",
    "    \n",
    "    #If the prediction matches the label column. Note that the label column is not used in the algo as it is skipped\n",
    "    #in the above functions.\n",
    "    try:\n",
    "        if predict(testnumpy[i],tree) == testnumpy[i][0]: counter += 1\n",
    "    except:\n",
    "    #Randomly choose a class as the prediction from above comment.\n",
    "        import random\n",
    "        classes = ['democrat','republican']\n",
    "        pred = random.choice(classes)\n",
    "        if pred == testnumpy[i][0]: counter += 1\n",
    "accuracy = counter/len(testnumpy)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: scikit learn for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9312977099236641"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a sklearns version to compare mine.\n",
    "\n",
    "#Convert all values into a numeric using sklearns Label Encoder, as sklearns is not able to handle strings.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "for i in range (0,trainFeatures.shape[1]):\n",
    "    trainFeatures[:,i] = labelencoder.fit_transform(trainFeatures[:,i])\n",
    "    \n",
    "for i in range (0,testFeatures.shape[1]):\n",
    "    testFeatures[:,i] = labelencoder.fit_transform(testFeatures[:,i])\n",
    "\n",
    "#Train the tree on entropy/ID3.\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf = clf.fit(trainFeatures,trainLabels)\n",
    "skpredict = clf.predict(testFeatures)\n",
    "\n",
    "#Calculate accuracy. \n",
    "skaccuracy = 0\n",
    "for i,j in zip(skpredict,testLabels):\n",
    "    if i==j: skaccuracy += 1\n",
    "skaccuracy/len(testLabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
