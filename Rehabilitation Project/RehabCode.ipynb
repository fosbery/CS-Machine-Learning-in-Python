{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CSC 8515 - Machine Learning Project  \n",
    "**Topic: Predicting success in rehabilitation  \n",
    "Author: James Fung  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#General.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#One hot encoder.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Split methods.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import svm\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "#Reduction Techniques.\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Visualizations\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "%matplotlib inline\n",
    "#Figure size.\n",
    "from matplotlib import rcParams\n",
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 7,5\n",
    "\n",
    "#Statistial packages.\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "#Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data, Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the rehab file as a pandas file.\n",
    "\n",
    "#Read the data.\n",
    "rehab = pd.read_csv('Rehab.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick look at the data.\n",
    "rehab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the first three columns as they provide no information. Also drop some \"FLG\" columns, as they are nearly uniform.\n",
    "rehabclean = rehab.drop(['Unnamed: 0','CASEID','DISYR','METHFLG','PCPFLG','HALLFLG','AMPHFLG','STIMFLG','TRNQFLG','BARBFLG','SEDHPFLG','INHFLG','OTCFLG','STFIPS','CBSA','REGION'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the column names?\n",
    "print(rehabclean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do the frequencies of the features look?\n",
    "#for i in rehabclean.columns:\n",
    "#    print('Information for '+i+':')\n",
    "#    print('')\n",
    "#    print((rehabclean[i].value_counts()/len(rehabclean))*100)\n",
    "#    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contain too many categories which may lead to noise. Will need to recategorize at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We're interested in if they completed a treatment, or if they did not due to some personal reason.\n",
    "#Filter rows to only those that interesting outcomes.\n",
    "\n",
    "#rehabclean = rehabclean.query('REASON in [\"TREATMENT COMPLETED\",\"TERMINATED BY FACILITY\",\"LEFT AGAINST PROFESSIONAL ADVICE\",\"INCARCERATED\",\"DEATH\"]')\n",
    "rehabclean = rehabclean.query('REASON in [\"TREATMENT COMPLETED\",\"LEFT AGAINST PROFESSIONAL ADVICE\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using the codebook provided by the CDC, missing values exist as \"MISSING/UNKNOWN/NOT COLLECTED/INVALID\" or -9.\n",
    "#Convert these values into \"NA\"\n",
    "rehabclean = rehabclean.replace(\"MISSING/UNKNOWN/NOT COLLECTED/INVALID\",np.NaN)\n",
    "rehabclean = rehabclean.replace(-9,np.NaN)\n",
    "\n",
    "#rehabclean = rehabclean.replace(\"MISSING/UNKNOWN/NOT COLLECTED/INVALID\",'MISSING')\n",
    "#rehabclean = rehabclean.replace(-9,'MISSING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Exploration\n",
    "\n",
    "What categories could potentially be related to whether they complete rehabilitation or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is there a relationship between the substance and the reason for leaving?\n",
    "sns.countplot(x=\"SUB1\", hue=\"REASON\",data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do these FLG columns provide any extra information apart from SUB?\n",
    "\n",
    "sns.countplot(x='MARFLG',hue='SUB1',data=rehabclean)\n",
    "\n",
    "#No - it appears that the column disappears if the flg is not reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's drop all of the remaining flg columns.\n",
    "rehabclean = rehabclean.drop(['ALCFLG','COKEFLG','MARFLG','HERFLG','OPSYNFLG','MTHAMFLG','BENZFLG','OTHERFLG'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Route dependent?\n",
    "sns.countplot(x=\"ROUTE1\", hue=\"REASON\",data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is there a relationship here to SUB1?\n",
    "sns.countplot(x=\"ROUTE1\", hue=\"SUB1\",data=rehabclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features pretty much directly relate to SUB. Let's try removing these from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean = rehabclean.drop(['ROUTE1','ROUTE2','ROUTE3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psychological problem?\n",
    "\n",
    "sns.countplot(x=\"PSYPROB\", hue=\"REASON\",data=rehabclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the patient has an addiction to alcohol, they seem to be able to complete rehab at a muc higher rate than more extreme drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age?\n",
    "sns.countplot(x=\"AGE\", hue=\"REASON\", order=['12-14','15-17','18-20','21-24','25-29','30-34','35-39',\n",
    "                                           '40-44','45-49','50-54','55 AND OVER'], data=rehabclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very young rehabilitation patients do not seem to be able to complete it as opposed to older patients (below 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RACE?\n",
    "sns.countplot(x=\"RACE\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minorities seem to complete it at a lower rate as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENDER?\n",
    "sns.countplot(x=\"GENDER\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females seem to complete it at a lower rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOMELESSNESS?\n",
    "sns.countplot(x=\"LIVARAG\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MARSTAT?\n",
    "sns.countplot(x=\"MARSTAT\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREG?\n",
    "sns.countplot(x=\"PREG\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How many missing values are in each column? What is the proportion?\n",
    "missing = ((rehabclean.isnull().sum()/len(rehabclean))*100).to_dict()\n",
    "missingsort = sorted(missing.items(),key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For features with less than 10% of missing values, append the to a list.\n",
    "autoimputelist = []\n",
    "\n",
    "for i in missingsort:\n",
    "    if i[1] > 0 and i[1] < 10:\n",
    "        autoimputelist.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For features with less than 10% of missing values, drop from dataset.\n",
    "\n",
    "rehabclean = rehabclean.dropna(subset=autoimputelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a new list of missing values.\n",
    "missing = ((rehabclean.isnull().sum()/len(rehabclean))*100).to_dict()\n",
    "missingsort = sorted(missing.items(),key=lambda kv: kv[1])\n",
    "\n",
    "largemissing = []\n",
    "\n",
    "for col in missingsort:\n",
    "    if col[1]>0:\n",
    "        print(col)\n",
    "        largemissing.append(col[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should I do about these features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For features 60% and over, let's examine some of them.\n",
    "rcParams['figure.figsize'] = 7,5\n",
    "#PREG?\n",
    "sns.countplot(x=\"PREG\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSMCRIT?\n",
    "rcParams['figure.figsize'] = 14,10\n",
    "g = sns.countplot(x=\"DSMCRIT\", hue=\"REASON\", data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"DETNLF\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.countplot(x=\"DETCRIM\", hue=\"REASON\", data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"FRSTUSE3\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(x=\"PRIMPAY\", hue=\"PRIMINC\", data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop features with missing values >60%.\n",
    "\n",
    "droplist = []\n",
    "\n",
    "for i in missingsort:\n",
    "    if i[1] > 60:\n",
    "        droplist.append(i[0])\n",
    "\n",
    "for i in droplist:\n",
    "    rehabclean = rehabclean.drop(i,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a new list of missing values.\n",
    "missing = ((rehabclean.isnull().sum()/len(rehabclean))*100).to_dict()\n",
    "missingsort = sorted(missing.items(),key=lambda kv: kv[1])\n",
    "\n",
    "largemissing = []\n",
    "\n",
    "for col in missingsort:\n",
    "    if col[1]>0:\n",
    "        print(col)\n",
    "        largemissing.append(col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are these columns worth imputing? Let's see how well they relate to the class label.\n",
    "\n",
    "#Perform a chi-squared test for PSYPROB on REASON.\n",
    "contingence = pd.crosstab(rehabclean['PSYPROB'],rehabclean['REASON'])\n",
    "\n",
    "chi2_contingency(contingence)\n",
    "\n",
    "#The p-value is 0, suggesting that there might be a relationship.\n",
    "\n",
    "#What about the other columns?\n",
    "for col in largemissing:\n",
    "    cont = pd.crosstab(rehabclean[col],rehabclean['REASON'])\n",
    "    val,pval,dof,exp = chi2_contingency(cont)\n",
    "    print(str(col) + \" : \" + str(round(pval,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all of these columns are statistically significant - will need to determine how to impute these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"HLTHINS\", hue=\"REASON\", data=rehabclean)\n",
    "\n",
    "#Doesn't seem significant - drop.\n",
    "rehabclean = rehabclean.drop(['HLTHINS'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"PRIMINC\", hue=\"REASON\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"PRIMINC\", hue=\"EMPLOY\", data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For those feature columns, replace with the most common label.\n",
    "#for column in largemissing:\n",
    "#    mode = rehabclean[str(column)].value_counts().idxmax()\n",
    "#    rehabclean[str(column)].fillna(mode,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try replacing all these missing values with -1.\n",
    "\n",
    "rehabclean = rehabclean.replace(np.NaN,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Recategorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Length of stay variable is sparse, must impute manually.\n",
    "#LOS < 30 is sparse, and is categorical, recombine into <30 days.\n",
    "LOSrecode = list(range(1,31))\n",
    "LOSrecode = list(map(str,LOSrecode))\n",
    "rehabclean['LOS'] = rehabclean['LOS'].replace(LOSrecode,'LESS THAN 30')\n",
    "\n",
    "#Replace missing values in LOS with most common.\n",
    "LOSmode = rehabclean['LOS'].value_counts().idxmax()\n",
    "rehabclean['LOS'].fillna(LOSmode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='LOS',hue='REASON',data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daywait is sparse, let's recode.\n",
    "rehabclean['DAYCAT'] = 'No Wait'\n",
    "rehabclean['DAYCAT'][rehabclean['DAYWAIT'] == 0] = 'No Wait'\n",
    "rehabclean['DAYCAT'][rehabclean['DAYWAIT'] > 0] = 'More than 0 days'\n",
    "\n",
    "rehabclean = rehabclean.drop('DAYWAIT',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='DAYCAT',hue='REASON',data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SUB's\n",
    "\n",
    "rehabclean.loc[rehabclean['SUB1'].value_counts()[rehabclean['SUB1']].values < 10000,'SUB1'] = \"OTHER\"\n",
    "rehabclean.loc[rehabclean['SUB2'].value_counts()[rehabclean['SUB2']].values < 10000,'SUB2'] = \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.countplot(x='SUB1',hue='REASON',data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='SUB2',hue='REASON',data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='FREQ1',hue='REASON',data=rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='FREQ2',hue='REASON',data=rehabclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like SUB2 doesn't really have as strong of a relationship to completion as SUB1. FREQ doesn't look very strong as well.\n",
    "\n",
    "Let's drop SUB2, SUB3, FREQ2, and FREQ3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean = rehabclean.drop(['SUB2','SUB3','FREQ2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What about ethnicity and race?\n",
    "\n",
    "g = sns.countplot(x='RACE',hue='REASON',data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "\n",
    "#Need to recode race.\n",
    "rehabclean.loc[rehabclean['RACE'].value_counts()[rehabclean['RACE']].values < 25000,'RACE'] = \"OTHER\"\n",
    "\n",
    "#Replot.\n",
    "g = sns.countplot(x='RACE',hue='REASON',data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop ethnicity as this is essentially correalated to race.\n",
    "\n",
    "rehabclean = rehabclean.drop(['ETHNIC'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop ALCDRUG, as SUB1 covers this already.\n",
    "rehabclean = rehabclean.drop(['ALCDRUG'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop FRSTUSE2, as FIRSTUSE1 covers.\n",
    "rehabclean = rehabclean.drop(['FRSTUSE2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVSETD.\n",
    "rehabclean.loc[rehabclean['SERVSETD'].value_counts()[rehabclean['SERVSETD']].values < 10000,'SERVSETD'] = \"OTHER\"\n",
    "\n",
    "g=sns.countplot(x='SERVSETD',hue='REASON',data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSOURCE.\n",
    "rehabclean.loc[rehabclean['PSOURCE'].value_counts()[rehabclean['PSOURCE']].values < 10000,'PSOURCE'] = \"OTHER\"\n",
    "\n",
    "g=sns.countplot(x='PSOURCE',hue='PRIMINC',data=rehabclean)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Manually encode ordinal variables to keep natural ordering.\n",
    "\n",
    "rehabclean['AGE'] = rehabclean['AGE'].map({'12-14':0,'15-17':1,'18-20':2,'21-24':3,\n",
    "                                                 '25-29':4,'30-34':5,'35-39':6,'40-44':7,\n",
    "                                                 '45-49':8,'50-54':9,'55 AND OVER':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['EDUC'] = rehabclean['EDUC'].map({'8 YEARS OR LESS':0,'9-11':1,'12':2,'13-15':3,\n",
    "                                                 '16 OR MORE':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['ARRESTS'] = rehabclean['ARRESTS'].map({'NONE':0,'ONCE':1,'2 OR MORE TIMES':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['LIVARAG'] = rehabclean['LIVARAG'].map({'HOMELESS':0,'DEPENDENT LIVING':1,'INDEPENDENT LIVING':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['FREQ1'] = rehabclean['FREQ1'].map({'NO USE IN THE PAST MONTH':0,\n",
    "                                                   '1-3 TIMES IN THE PAST MONTH':1,\n",
    "                                                   '1-2 TIMES IN THE PAST WEEK':2,\n",
    "                                                  '3-6 TIMES IN THE PAST WEEK':3,\n",
    "                                                  'DAILY':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['NOPRIOR'] = rehabclean['NOPRIOR'].map({'NO PRIOR TREATMENT EPISODE':0,\n",
    "                                                   '1 PRIOR TREATMENT EPISODES':1,\n",
    "                                                   '2 PRIOR TREATMENT EPISODES':2,\n",
    "                                                  '3 PRIOR TREATMENT EPISODES':3,\n",
    "                                                  '4 PRIOR TREATMENT EPISODES':4,\n",
    "                                                  '5 OR MORE PRIOR TREATMENT EPISODES':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['FRSTUSE1'] = rehabclean['FRSTUSE1'].map({'11 AND UNDER':0,'12-14':1,'15-17':2,'18-20':3,'21-24':4,\n",
    "                                                 '25-29':5,'30-34':6,'35-39':7,'40-44':8,\n",
    "                                                 '45-49':9,'50-54':10,'55 AND OVER':11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['LOS'] = rehabclean['LOS'].map({'LESS THAN 30':0,'31 TO 45 DAYS':1,'46 TO 60 DAYS':2,\n",
    "                                           '61 TO 90 DAYS':3,'91 TO 120 DAYS':4,\n",
    "                                                 '121 TO 180 DAYS':5,'181 TO 365 DAYS':6,'MORE THAN A YEAR':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabtest = rehabclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode the binary columns.\n",
    "def recat(colnames):\n",
    "    for col in colnames:\n",
    "        rehabtest[col] = rehabtest[col].astype('category')\n",
    "        rehabtest[col] = rehabtest[col].cat.codes\n",
    "\n",
    "recat(['GENDER','VET','METHUSE','LOS','PSYPROB','DAYCAT']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One hot encode multicategory.\n",
    "\n",
    "rehabtest = pd.get_dummies(rehabtest,columns=['RACE','MARSTAT','EMPLOY','VET',\n",
    "                                                     'PRIMINC','DIVISION','SERVSETD','PSOURCE','SUB1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "\n",
    "Could we reduce this dataset into two components? Will it mean anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=rehabtest.iloc[:,rehabtest.columns != 'REASON']\n",
    "Y=rehabtest.iloc[:,rehabtest.columns == 'REASON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a PCA learner\n",
    "pca = PCA(n_components = 2)\n",
    "eigenbasis = pca.fit(X)\n",
    "rehab2d = eigenbasis.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's also look at how much of the total variance we were able to cover with 2 dimensions\n",
    "print('percentage of variance explained:', sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(rehab2d[:,0],rehab2d[:,1],hue=Y.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Utilizer a TSNE learner.\n",
    "\n",
    "#Randomly sample the data, as many of these algorithms took way too long to run on 750k.\n",
    "\n",
    "sample = rehabtest.sample(n=10000)\n",
    "\n",
    "Xs=sample.iloc[:,rehabtest.columns != 'REASON']\n",
    "Ys=sample.iloc[:,rehabtest.columns == 'REASON']\n",
    "\n",
    "td = TSNE(n_components=2).fit_transform(Xs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sns.scatterplot(td[:,0],td[:,1],hue=Ys.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split this into features and labels, and run a test algorithm.\n",
    "\n",
    "PCAlabels = Y.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(rehab2d,PCAlabels,test_size=.3)\n",
    "\n",
    "#Train on a neural network.\n",
    "neural = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(15,),random_state=1)\n",
    "neural = neural.fit(X_train,y_train)\n",
    "y_pred = neural.predict(X_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train on a random forest.\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use recursive feature elimination.\n",
    "#Create a baseline classifier from a robust model, used ot evaluate a subset of attributes.\n",
    "\n",
    "rf = LogisticRegression()\n",
    "#rf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "#Create the RFE model and select 3 attributes.\n",
    "rfe = RFE(rf, n_features_to_select=5)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "\n",
    "#Summarise the selection of the attributes.\n",
    "print(rfe.support_)\n",
    "print sorted(zip(map(lambda x:round(x,4),rfe.ranking_),rehabtest.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rehabclean['REASON'].value_counts()/len(rehabclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the data into features and labels, and split into training and testing data.\n",
    "\n",
    "X=rehabtest.iloc[:,rehabtest.columns != 'REASON']\n",
    "Y=rehabtest.iloc[:,rehabtest.columns == 'REASON']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on a random forest.\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "#Train on a decision tree, checking to see the optimal depth.\n",
    "for i in range(0,len(X.columns)):\n",
    "    tr = tree.DecisionTreeClassifier(max_depth=i+1)\n",
    "    tr = tr.fit(X_train,y_train.values.ravel())\n",
    "    y_pred = tr.predict(X_test)\n",
    "\n",
    "    print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "    accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "    scores[i+1] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tr = tree.DecisionTreeClassifier(max_depth=14)\n",
    "tr = tree.DecisionTreeClassifier(max_depth=3)\n",
    "tr = tr.fit(X_train,y_train.values.ravel())\n",
    "y_pred = tr.predict(X_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(tr, out_file = None,\n",
    "                                feature_names = X.columns,\n",
    "                               class_names = Y['REASON'].unique(),\n",
    "                               filled = True, rounded = True,\n",
    "                               special_characters = True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('Rehab Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For neural networks, one would need to normalize the features. Let's use sklearn to do this.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "normalizedX = preprocessing.normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on a neural network.\n",
    "#neural = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(15,),random_state=1)\n",
    "neural = MLPClassifier()\n",
    "neural = neural.fit(X_train,y_train.values.ravel())\n",
    "y_pred = neural.predict(X_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost on full set.\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred=ada.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train on SVM.\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs,Ys,test_size=.3)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train on kNN.\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh = neigh.fit(X_train,y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train on XGBoost.\n",
    "boost = XGBClassifier()\n",
    "boost = boost.fit(X_train,y_train)\n",
    "y_pred = boost.predict(X_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on logistic regression.\n",
    "logreg = LogisticRegression()\n",
    "logreg = logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### k-fold Cross Validation\n",
    "\n",
    "From above, I determined that the model with the best goal in mind, predicting unsuccesful patients, was the neural network as that had the lowest recall.\n",
    "\n",
    "Lets' perform k-fold cross validation to check the stability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 4)\n",
    "\n",
    "neural = MLPClassifier()\n",
    "\n",
    "nnScores = cross_val_score(neural, X, Y.values.ravel(), cv = rkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from statistics import variance\n",
    "\n",
    "print(mean(nnScores))\n",
    "print(variance(nnScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty stable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "neural = MLPClassifier()\n",
    "\n",
    "rs = RandomizedSearchCV(neural, param_distributions={\n",
    "    'learning_rate_init': stats.uniform(0.001, 0.05),\n",
    "    'hidden_layer_sizes': stats.randint(4, 200),\n",
    "    'activation': [\"logistic\", \"tanh\", \"relu\"]})\n",
    "rs.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rs.predict(X_test)\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
