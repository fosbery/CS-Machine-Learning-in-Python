{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CSC 8515 - Machine Learning Project  \n",
        "**Topic: Predicting success in rehabilitation  \n",
        "Author: James Fung  **"
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#General.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "#One hot encoder.\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "#Split methods.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Models\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree, svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#Reduction Techniques.\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#Visualizations\n",
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "%matplotlib inline\n",
        "#Figure size.\n",
        "from matplotlib import rcParams\n",
        "# figure size in inches\n",
        "rcParams['figure.figsize'] = 7,5\n",
        "\n",
        "#Statistial packages.\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "#Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\nfrom sklearn.model_selection import RepeatedKFold, cross_val_score"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data, Feature Exploration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the rehab file as a pandas file.\n",
        "\n",
        "#Read the data.\n",
        "rehab = pd.read_csv('Rehab.csv', header=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Quick look at the data.\n",
        "rehab.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop the first three columns as they provide no information. Also drop some \"FLG\" columns, as they are nearly uniform.\n",
        "rehabclean = rehab.drop(['Unnamed: 0','CASEID','DISYR','METHFLG','PCPFLG','HALLFLG','AMPHFLG','STIMFLG','TRNQFLG','BARBFLG','SEDHPFLG','INHFLG','OTCFLG','STFIPS','CBSA','REGION'],1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What are the column names?\n",
        "print(rehabclean.columns)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#How do the frequencies of the features look?\n",
        "#for i in rehabclean.columns:\n",
        "#    print('Information for '+i+':')\n",
        "#    print('')\n",
        "#    print((rehabclean[i].value_counts()/len(rehabclean))*100)\n",
        "#    print('----------------------------------')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some columns contain too many categories which may lead to noise. Will need to recategorize at some point."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#We're interested in if they completed a treatment, or if they did not due to some personal reason.\n",
        "#Filter rows to only those that interesting outcomes.\n",
        "\n",
        "#rehabclean = rehabclean.query('REASON in [\"TREATMENT COMPLETED\",\"TERMINATED BY FACILITY\",\"LEFT AGAINST PROFESSIONAL ADVICE\",\"INCARCERATED\",\"DEATH\"]')\n",
        "rehabclean = rehabclean.query('REASON in [\"TREATMENT COMPLETED\",\"LEFT AGAINST PROFESSIONAL ADVICE\"]')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the codebook provided by the CDC, missing values exist as \"MISSING/UNKNOWN/NOT COLLECTED/INVALID\" or -9.\n",
        "#Convert these values into \"NA\"\n",
        "rehabclean = rehabclean.replace(\"MISSING/UNKNOWN/NOT COLLECTED/INVALID\",np.NaN)\n",
        "rehabclean = rehabclean.replace(-9,np.NaN)\n",
        "\n",
        "#rehabclean = rehabclean.replace(\"MISSING/UNKNOWN/NOT COLLECTED/INVALID\",'MISSING')\n",
        "#rehabclean = rehabclean.replace(-9,'MISSING')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Exploration\n",
        "\nWhat categories could potentially be related to whether they complete rehabilitation or not?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Is there a relationship between the substance and the reason for leaving?\n",
        "sns.countplot(x=\"SUB1\", hue=\"REASON\",data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Do these FLG columns provide any extra information apart from SUB?\n",
        "\n",
        "sns.countplot(x='MARFLG',hue='SUB1',data=rehabclean)\n",
        "\n#No - it appears that the column disappears if the flg is not reported."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's drop all of the remaining flg columns.\n",
        "rehabclean = rehabclean.drop(['ALCFLG','COKEFLG','MARFLG','HERFLG','OPSYNFLG','MTHAMFLG','BENZFLG','OTHERFLG'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Route dependent?\n",
        "sns.countplot(x=\"ROUTE1\", hue=\"REASON\",data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Is there a relationship here to SUB1?\n",
        "sns.countplot(x=\"ROUTE1\", hue=\"SUB1\",data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "These features pretty much directly relate to SUB. Let's try removing these from the dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean = rehabclean.drop(['ROUTE1','ROUTE2','ROUTE3'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Psychological problem?\n",
        "\nsns.countplot(x=\"PSYPROB\", hue=\"REASON\",data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the patient has an addiction to alcohol, they seem to be able to complete rehab at a muc higher rate than more extreme drugs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Age?\n",
        "sns.countplot(x=\"AGE\", hue=\"REASON\", order=['12-14','15-17','18-20','21-24','25-29','30-34','35-39',\n",
        "                                           '40-44','45-49','50-54','55 AND OVER'], data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very young rehabilitation patients do not seem to be able to complete it as opposed to older patients (below 20)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#RACE?\n",
        "sns.countplot(x=\"RACE\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minorities seem to complete it at a lower rate as well."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#GENDER?\n",
        "sns.countplot(x=\"GENDER\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Females seem to complete it at a lower rate."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#HOMELESSNESS?\n",
        "sns.countplot(x=\"LIVARAG\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#MARSTAT?\n",
        "sns.countplot(x=\"MARSTAT\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#PREG?\n",
        "sns.countplot(x=\"PREG\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Value Imputation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#How many missing values are in each column? What is the proportion?\n",
        "missing = ((rehabclean.isnull().sum()/len(rehabclean))*100).to_dict()\n",
        "missingsort = sorted(missing.items(),key=lambda kv: kv[1])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missingsort"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#For features with less than 10% of missing values, append the to a list.\n",
        "autoimputelist = []\n",
        "\n",
        "for i in missingsort:\n",
        "    if i[1] > 0 and i[1] < 10:\n",
        "        autoimputelist.append(i[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For features with less than 10% of missing values, drop from dataset.\n",
        "\nrehabclean = rehabclean.dropna(subset=autoimputelist)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Produce a new list of missing values.\n",
        "missing = ((rehabclean.isnull().sum()/len(rehabclean))*100).to_dict()\n",
        "missingsort = sorted(missing.items(),key=lambda kv: kv[1])\n",
        "\n",
        "largemissing = []\n",
        "\n",
        "for col in missingsort:\n",
        "    if col[1]>0:\n",
        "        print(col)\n",
        "        largemissing.append(col[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "What should I do about these features?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#For features 60% and over, let's examine some of them.\n",
        "rcParams['figure.figsize'] = 7,5\n",
        "#PREG?\n",
        "sns.countplot(x=\"PREG\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#DSMCRIT?\n",
        "rcParams['figure.figsize'] = 14,10\n",
        "g = sns.countplot(x=\"DSMCRIT\", hue=\"REASON\", data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"DETNLF\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "g=sns.countplot(x=\"DETCRIM\", hue=\"REASON\", data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"FRSTUSE3\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.countplot(x=\"PRIMPAY\", hue=\"PRIMINC\", data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop features with missing values >60%.\n",
        "\n",
        "droplist = []\n",
        "\n",
        "for i in missingsort:\n",
        "    if i[1] > 60:\n",
        "        droplist.append(i[0])\n",
        "\n",
        "for i in droplist:\n",
        "    rehabclean = rehabclean.drop(i,axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Produce a new list of missing values.\n",
        "missing = ((rehabclean.isnull().sum()/len(rehabclean))*100).to_dict()\n",
        "missingsort = sorted(missing.items(),key=lambda kv: kv[1])\n",
        "\n",
        "largemissing = []\n",
        "\n",
        "for col in missingsort:\n",
        "    if col[1]>0:\n",
        "        print(col)\n",
        "        largemissing.append(col[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Are these columns worth imputing? Let's see how well they relate to the class label.\n",
        "\n",
        "#Perform a chi-squared test for PSYPROB on REASON.\n",
        "contingence = pd.crosstab(rehabclean['PSYPROB'],rehabclean['REASON'])\n",
        "\n",
        "chi2_contingency(contingence)\n",
        "\n",
        "#The p-value is 0, suggesting that there might be a relationship.\n",
        "\n",
        "#What about the other columns?\n",
        "for col in largemissing:\n",
        "    cont = pd.crosstab(rehabclean[col],rehabclean['REASON'])\n",
        "    val,pval,dof,exp = chi2_contingency(cont)\n",
        "    print(str(col) + \" : \" + str(round(pval,2)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nearly all of these columns are statistically significant - will need to determine how to impute these."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"HLTHINS\", hue=\"REASON\", data=rehabclean)\n",
        "\n",
        "#Doesn't seem significant - drop.\n",
        "rehabclean = rehabclean.drop(['HLTHINS'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"PRIMINC\", hue=\"REASON\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"PRIMINC\", hue=\"EMPLOY\", data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#For those feature columns, replace with the most common label.\n",
        "#for column in largemissing:\n",
        "#    mode = rehabclean[str(column)].value_counts().idxmax()\n",
        "#    rehabclean[str(column)].fillna(mode,inplace=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Try replacing all these missing values with -1.\n",
        "\nrehabclean = rehabclean.replace(np.NaN,-1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Recategorization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Length of stay variable is sparse, must impute manually.\n",
        "#LOS < 30 is sparse, and is categorical, recombine into <30 days.\n",
        "LOSrecode = list(range(1,31))\n",
        "LOSrecode = list(map(str,LOSrecode))\n",
        "rehabclean['LOS'] = rehabclean['LOS'].replace(LOSrecode,'LESS THAN 30')\n",
        "\n",
        "#Replace missing values in LOS with most common.\n",
        "LOSmode = rehabclean['LOS'].value_counts().idxmax()\n",
        "rehabclean['LOS'].fillna(LOSmode, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='LOS',hue='REASON',data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Daywait is sparse, let's recode.\n",
        "rehabclean['DAYCAT'] = 'No Wait'\n",
        "rehabclean['DAYCAT'][rehabclean['DAYWAIT'] == 0] = 'No Wait'\n",
        "rehabclean['DAYCAT'][rehabclean['DAYWAIT'] > 0] = 'More than 0 days'\n",
        "\nrehabclean = rehabclean.drop('DAYWAIT',axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='DAYCAT',hue='REASON',data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#SUB's\n",
        "\n",
        "rehabclean.loc[rehabclean['SUB1'].value_counts()[rehabclean['SUB1']].values < 10000,'SUB1'] = \"OTHER\"\n",
        "rehabclean.loc[rehabclean['SUB2'].value_counts()[rehabclean['SUB2']].values < 10000,'SUB2'] = \"OTHER\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g=sns.countplot(x='SUB1',hue='REASON',data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='SUB2',hue='REASON',data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='FREQ1',hue='REASON',data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='FREQ2',hue='REASON',data=rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like SUB2 doesn't really have as strong of a relationship to completion as SUB1. FREQ doesn't look very strong as well.\n",
        "\nLet's drop SUB2, SUB3, FREQ2, and FREQ3."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean = rehabclean.drop(['SUB2','SUB3','FREQ2'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What about ethnicity and race?\n",
        "\n",
        "g = sns.countplot(x='RACE',hue='REASON',data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
        "\n",
        "#Need to recode race.\n",
        "rehabclean.loc[rehabclean['RACE'].value_counts()[rehabclean['RACE']].values < 25000,'RACE'] = \"OTHER\"\n",
        "\n",
        "#Replot.\n",
        "g = sns.countplot(x='RACE',hue='REASON',data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop ethnicity as this is essentially correalated to race.\n",
        "\nrehabclean = rehabclean.drop(['ETHNIC'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop ALCDRUG, as SUB1 covers this already.\n",
        "rehabclean = rehabclean.drop(['ALCDRUG'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop FRSTUSE2, as FIRSTUSE1 covers.\n",
        "rehabclean = rehabclean.drop(['FRSTUSE2'],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SERVSETD.\n",
        "rehabclean.loc[rehabclean['SERVSETD'].value_counts()[rehabclean['SERVSETD']].values < 10000,'SERVSETD'] = \"OTHER\"\n",
        "\n",
        "g=sns.countplot(x='SERVSETD',hue='REASON',data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#PSOURCE.\n",
        "rehabclean.loc[rehabclean['PSOURCE'].value_counts()[rehabclean['PSOURCE']].values < 10000,'PSOURCE'] = \"OTHER\"\n",
        "\n",
        "g=sns.countplot(x='PSOURCE',hue='PRIMINC',data=rehabclean)\n",
        "g.set_xticklabels(g.get_xticklabels(),rotation=45)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Testing"
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoding section:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Manually encode ordinal variables to keep natural ordering.\n",
        "\n",
        "rehabclean['AGE'] = rehabclean['AGE'].map({'12-14':0,'15-17':1,'18-20':2,'21-24':3,\n",
        "                                                 '25-29':4,'30-34':5,'35-39':6,'40-44':7,\n",
        "                                                 '45-49':8,'50-54':9,'55 AND OVER':10})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['EDUC'] = rehabclean['EDUC'].map({'8 YEARS OR LESS':0,'9-11':1,'12':2,'13-15':3,\n",
        "                                                 '16 OR MORE':4})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['ARRESTS'] = rehabclean['ARRESTS'].map({'NONE':0,'ONCE':1,'2 OR MORE TIMES':2})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['LIVARAG'] = rehabclean['LIVARAG'].map({'HOMELESS':0,'DEPENDENT LIVING':1,'INDEPENDENT LIVING':2})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['FREQ1'] = rehabclean['FREQ1'].map({'NO USE IN THE PAST MONTH':0,\n",
        "                                                   '1-3 TIMES IN THE PAST MONTH':1,\n",
        "                                                   '1-2 TIMES IN THE PAST WEEK':2,\n",
        "                                                  '3-6 TIMES IN THE PAST WEEK':3,\n",
        "                                                  'DAILY':4})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['NOPRIOR'] = rehabclean['NOPRIOR'].map({'NO PRIOR TREATMENT EPISODE':0,\n",
        "                                                   '1 PRIOR TREATMENT EPISODES':1,\n",
        "                                                   '2 PRIOR TREATMENT EPISODES':2,\n",
        "                                                  '3 PRIOR TREATMENT EPISODES':3,\n",
        "                                                  '4 PRIOR TREATMENT EPISODES':4,\n",
        "                                                  '5 OR MORE PRIOR TREATMENT EPISODES':5})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['FRSTUSE1'] = rehabclean['FRSTUSE1'].map({'11 AND UNDER':0,'12-14':1,'15-17':2,'18-20':3,'21-24':4,\n",
        "                                                 '25-29':5,'30-34':6,'35-39':7,'40-44':8,\n",
        "                                                 '45-49':9,'50-54':10,'55 AND OVER':11})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['LOS'] = rehabclean['LOS'].map({'LESS THAN 30':0,'31 TO 45 DAYS':1,'46 TO 60 DAYS':2,\n",
        "                                           '61 TO 90 DAYS':3,'91 TO 120 DAYS':4,\n",
        "                                                 '121 TO 180 DAYS':5,'181 TO 365 DAYS':6,'MORE THAN A YEAR':7})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rehabtest = rehabclean"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode the binary columns.\n",
        "def recat(colnames):\n",
        "    for col in colnames:\n",
        "        rehabtest[col] = rehabtest[col].astype('category')\n",
        "        rehabtest[col] = rehabtest[col].cat.codes\n",
        "\nrecat(['GENDER','VET','METHUSE','LOS','PSYPROB','DAYCAT']) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encode multicategory.\n",
        "\n",
        "rehabtest = pd.get_dummies(rehabtest,columns=['RACE','MARSTAT','EMPLOY','VET',\n",
        "                                                     'PRIMINC','DIVISION','SERVSETD','PSOURCE','SUB1'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimensionality Reduction\n",
        "\nCould we reduce this dataset into two components? Will it mean anything?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X=rehabtest.iloc[:,rehabtest.columns != 'REASON']\n",
        "Y=rehabtest.iloc[:,rehabtest.columns == 'REASON']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up a PCA learner\n",
        "pca = PCA(n_components = 2)\n",
        "eigenbasis = pca.fit(X)\n",
        "rehab2d = eigenbasis.transform(X)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's also look at how much of the total variance we were able to cover with 2 dimensions\n",
        "print('percentage of variance explained:', sum(pca.explained_variance_ratio_))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(rehab2d[:,0],rehab2d[:,1],hue=Y.values.flatten())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilizer a TSNE learner.\n",
        "\n",
        "#Randomly sample the data, as many of these algorithms took way too long to run on 750k.\n",
        "\n",
        "sample = rehabtest.sample(n=10000)\n",
        "\n",
        "Xs=sample.iloc[:,rehabtest.columns != 'REASON']\n",
        "Ys=sample.iloc[:,rehabtest.columns == 'REASON']\n",
        "\ntd = TSNE(n_components=2).fit_transform(Xs)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "raw",
      "source": [
        "sns.scatterplot(td[:,0],td[:,1],hue=Ys.values.flatten())"
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split this into features and labels, and run a test algorithm.\n",
        "\n",
        "PCAlabels = Y.values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(rehab2d,PCAlabels,test_size=.3)\n",
        "\n",
        "#Train on a neural network.\n",
        "neural = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(15,),random_state=1)\n",
        "neural = neural.fit(X_train,y_train)\n",
        "y_pred = neural.predict(X_test)\n",
        "\nprint('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on a random forest.\n",
        "\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Use recursive feature elimination.\n",
        "#Create a baseline classifier from a robust model, used ot evaluate a subset of attributes.\n",
        "\n",
        "rf = LogisticRegression()\n",
        "#rf = RandomForestClassifier(n_estimators=10)\n",
        "\n",
        "#Create the RFE model and select 3 attributes.\n",
        "rfe = RFE(rf, n_features_to_select=5)\n",
        "rfe = rfe.fit(X_train,y_train)\n",
        "\n",
        "#Summarise the selection of the attributes.\n",
        "print(rfe.support_)\n",
        "print sorted(zip(map(lambda x:round(x,4),rfe.ranking_),rehabtest.columns)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rehabclean['REASON'].value_counts()/len(rehabclean)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into features and labels, and split into training and testing data.\n",
        "\n",
        "X=rehabtest.iloc[:,rehabtest.columns != 'REASON']\n",
        "Y=rehabtest.iloc[:,rehabtest.columns == 'REASON']\n",
        "\nX_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=.3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on a random forest.\n",
        "\n",
        "rf=RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred=rf.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
        "                                   index = X_train.columns,\n",
        "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
        "feature_importances"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "\n",
        "#Train on a decision tree, checking to see the optimal depth.\n",
        "for i in range(0,len(X.columns)):\n",
        "    tr = tree.DecisionTreeClassifier(max_depth=i+1)\n",
        "    tr = tr.fit(X_train,y_train.values.ravel())\n",
        "    y_pred = tr.predict(X_test)\n",
        "\n",
        "    print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
        "    accuracy = metrics.accuracy_score(y_test,y_pred)\n",
        "    scores[i+1] = accuracy"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tr = tree.DecisionTreeClassifier(max_depth=14)\n",
        "tr = tree.DecisionTreeClassifier(max_depth=3)\n",
        "tr = tr.fit(X_train,y_train.values.ravel())\n",
        "y_pred = tr.predict(X_test)\n",
        "\nprint('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "dot_data = tree.export_graphviz(tr, out_file = None,\n",
        "                                feature_names = X.columns,\n",
        "                               class_names = Y['REASON'].unique(),\n",
        "                               filled = True, rounded = True,\n",
        "                               special_characters = True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render('Rehab Tree')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For neural networks, one would need to normalize the features. Let's use sklearn to do this.\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\nnormalizedX = preprocessing.normalize(X_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on a neural network.\n",
        "#neural = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(15,),random_state=1)\n",
        "neural = MLPClassifier()\n",
        "neural = neural.fit(X_train,y_train.values.ravel())\n",
        "y_pred = neural.predict(X_test)\n",
        "\n",
        "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
        "\nprint(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaboost on full set.\n",
        "\n",
        "ada = AdaBoostClassifier(n_estimators=100)\n",
        "ada.fit(X_train,y_train)\n",
        "y_pred=ada.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
        "\nprint(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on SVM.\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xs,Ys,test_size=.3)\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on kNN.\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh = neigh.fit(X_train,y_train)\n",
        "y_pred = neigh.predict(X_test)\n",
        "\nprint('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on XGBoost.\n",
        "boost = XGBClassifier()\n",
        "boost = boost.fit(X_train,y_train)\n",
        "y_pred = boost.predict(X_test)\n",
        "\n",
        "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
        "\nprint(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train on logistic regression.\n",
        "logreg = LogisticRegression()\n",
        "logreg = logreg.fit(X_train,y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "\nprint('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\nprint(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k-fold Cross Validation\n",
        "\n",
        "From above, I determined that the model with the best goal in mind, predicting unsuccesful patients, was the neural network as that had the lowest recall.\n",
        "\nLets' perform k-fold cross validation to check the stability of the model."
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rkf = RepeatedKFold(n_splits = 5, n_repeats = 4)\n",
        "\n",
        "neural = MLPClassifier()\n",
        "\nnnScores = cross_val_score(neural, X, Y.values.ravel(), cv = rkf)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nnScores"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "from statistics import variance\n",
        "\n",
        "print(mean(nnScores))\n",
        "print(variance(nnScores))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks pretty stable!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.grid_search import RandomizedSearchCV\n",
        "from scipy import stats\n",
        "\n",
        "neural = MLPClassifier()\n",
        "\n",
        "rs = RandomizedSearchCV(neural, param_distributions={\n",
        "    'learning_rate_init': stats.uniform(0.001, 0.05),\n",
        "    'hidden_layer_sizes': stats.randint(4, 200),\n",
        "    'activation': [\"logistic\", \"tanh\", \"relu\"]})\n",
        "rs.fit(X_train, y_train.values.ravel())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rs.predict(X_test)\n",
        "\nprint('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=['LEFT AGAINST PROFESSIONAL ADVICE','SUCCESFUL']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}